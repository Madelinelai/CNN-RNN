{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madelinelai/CNN-RNN/blob/main/2_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kxczC9t8Ky4"
      },
      "source": [
        "第一部分：\n",
        "\n",
        "介紹如何用 PyTorch 訓練自己的 convolutional neural network\n",
        "\n",
        "第二部份：\n",
        "\n",
        "1. 資料預處理\n",
        "1. 資料增強 (data augmentation)\n",
        "1. 測試時的資料增強 (test time augmentation)\n",
        "\n",
        "第三部份：\n",
        "\n",
        "預訓練模型\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF3HNe2O8E47",
        "outputId": "250f944d-7e11-42d4-84f4-d385dd37aa81"
      },
      "source": [
        "!pip freeze | grep albumentations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "albumentations==0.1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tsfX58m-8_KQ",
        "outputId": "6a02ffbe-0a74-4c33-e941-6925f4188da4"
      },
      "source": [
        "!pip install albumentations==0.4.3\n",
        "!pip install matplotlib==3.1.3\n",
        "!pip install numpy==1.18.2\n",
        "!pip install torch==1.4.0\n",
        "!pip install torchvision==0.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations==0.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/c4/a1e6ac237b5a27874b01900987d902fe83cc469ebdb09eb72a68c4329e78/albumentations-0.4.3.tar.gz (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.3) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.3) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.3) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.3) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (2.4.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (4.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3) (2.8.1)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.3-cp37-none-any.whl size=60780 sha256=a3da0e0da80d4212bbac4e19748cd5bb19e30a4f17c3f7de5770e842030d7cdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/16/8e/d3bec34bf30adff30929226f0b83cc8c005b5af131f51db9d0\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp37-none-any.whl size=654019 sha256=23547c722f677ce10f7055fb2d56628381fd97cf64687c51a60c6ecc0c9d8d41\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.3 imgaug-0.2.6\n",
            "Collecting matplotlib==3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/9b/35ab3469fd1509f7636a344940569ebfd33239673fd2318e80b4700a257c/matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1MB 227kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.1.3) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed matplotlib-3.1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.18.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/ce/d0b92f0283faa4da76ea82587ff9da70104e81f59ba14f76c87e4196254e/numpy-1.18.2-cp37-cp37m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 7.7MB/s \n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.18.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.18.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.18.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 24kB/s \n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "Successfully installed torch-1.4.0\n",
            "Collecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.18.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (7.1.2)\n",
            "Installing collected packages: torchvision\n",
            "  Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Successfully installed torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWkaxU33ADdf"
      },
      "source": [
        "import os\n",
        "import platform\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eXkOewz-YWa",
        "outputId": "180204e4-1683-44b4-80c8-4bee2bd35f10"
      },
      "source": [
        "# 下載 cifar 10 影像資料並解壓縮\n",
        "# cifar 10 介紹：https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!tar -xzvf cifar-10-python.tar.gz\n",
        "!rm cifar-10-python.tar.gz "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-16 15:38:49--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  44.1MB/s    in 4.1s    \n",
            "\n",
            "2021-07-16 15:38:53 (39.3 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "bLD7zg8P_EDA",
        "outputId": "26ec4f62-749b-4aa4-ed11-a2b8dfa0e3fa"
      },
      "source": [
        "def load_batch(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = pickle.load(f, encoding='latin-1')\n",
        "    # print(datadict)\n",
        "    feature = datadict['data']\n",
        "    label = datadict['labels']\n",
        "    feature = feature.reshape(10000, 3, 32, 32).astype(\"float\")\n",
        "    label = np.array(label)\n",
        "    return feature, label\n",
        "\n",
        "cifar_dir = 'cifar-10-batches-py'\n",
        "train_feature = []\n",
        "train_label = []\n",
        "for i in range(5):\n",
        "    f = os.path.join(cifar_dir, 'data_batch_%d' % (i + 1))\n",
        "    feature_i, label_i = load_batch(f)\n",
        "    train_feature.append(feature_i)\n",
        "    train_label.append(label_i)\n",
        "train_feature = np.concatenate(train_feature).transpose(0, 2, 3, 1)\n",
        "train_label = np.concatenate(train_label)\n",
        "del feature_i, label_i\n",
        "test_feature, test_label = load_batch(os.path.join(cifar_dir, 'test_batch'))\n",
        "test_feature = test_feature.transpose(0, 2, 3, 1)\n",
        "\n",
        "print(train_feature.shape, train_label.shape, test_feature.shape, test_label.shape)\n",
        "print(train_feature[0].min(), train_feature[0].max())\n",
        "# channel, x, y to x, y, channel\n",
        "plt.imshow(train_feature[0].astype(np.uint8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n",
            "0.0 255.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0a1d4dafd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMPty7WSHRUI"
      },
      "source": [
        "# 切出訓練集跟驗證集\n",
        "np.random.seed(551335114)\n",
        "index = np.arange(train_feature.shape[0])\n",
        "np.random.shuffle(index)\n",
        "\n",
        "train_feature, val_feature = train_feature[index[:45000]], train_feature[index[45000:]]\n",
        "train_label, val_label = train_label[index[:45000]], train_label[index[45000:]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQijY9fJK6GD"
      },
      "source": [
        "建立訓練環境：\n",
        "\n",
        "1. 寫好模型\n",
        "\n",
        "1. 寫好讀取資料的 Dataset class\n",
        "\n",
        "1. 將資料逐一讀出訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtXsaP4LHLbJ"
      },
      "source": [
        "# 建立自己的 CNN\n",
        "# 圖片輸入 => conv => relu => pooling => conv => pooling => feedforward (fully connected)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5)\n",
        "        # 可以用 https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveMaxPool2d 就不用算維度算得這麼辛苦\n",
        "        self.fc = nn.Linear(25 * 64, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x = batch_size x 3 x 32 x 32\n",
        "        x = F.relu(self.conv1(x), 2)\n",
        "        # x = batch_size x 64 x 28 x 28\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        # x = batch_size x 64 x 14 x 14\n",
        "        x = F.relu(self.conv2(x), 2)\n",
        "        # x = batch_size x 64 x 10 x 10\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        # x = batch_size x 64 x 5 x 5 (除不盡會被捨去 https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d )\n",
        "        # flatten, 變成二維 -1 表示自動計算，25(= 5 x 5) 是圖的大小，64 是 conv2 output 64 個 filter\n",
        "        # 變成 batch_size x 1600\n",
        "        x = x.view(-1, 25 * 64)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrSImOw6LWT3"
      },
      "source": [
        "class CifarDataset(Dataset):\n",
        "    def __init__(self, feature, label=None, train_mean=None, train_std=None):\n",
        "        self.feature = feature\n",
        "        self.label = label\n",
        "        self.train_mean = train_mean\n",
        "        self.train_std = train_std\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.feature[idx]\n",
        "        if self.train_mean is not None and self.train_std is not None:\n",
        "            feature = (feature - self.train_mean) / self.train_std\n",
        "        # PyTorch 使用 (channel, height, width)\n",
        "        feature = np.transpose(feature, (2, 0, 1))\n",
        "        if self.label is not None:\n",
        "            return feature, self.label[idx]\n",
        "        else:\n",
        "            return feature\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.feature.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3SPJMdArg1B"
      },
      "source": [
        "# **Cross entropy loss**\n",
        "\n",
        "https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a7Ig478L8bq"
      },
      "source": [
        "def train_model(model_class, train_dataset, val_dataset, max_epoch=100, patient=5, lr=1e-3, name=None, batch_size=64):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    best_loss = np.inf\n",
        "    best_epoch = -1\n",
        "    # optimize cross entropy loss\n",
        "    # https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model = model_class()\n",
        "    # print(model)\n",
        "    model.cuda()  # 使用 GPU\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    for epoch in range(max_epoch):\n",
        "        model.train()  # 訓練模式\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        # 通常深度學習使用的資料量都很大，無法一次讀入 GPU，所以每次只訓練 batch_size 筆資料\n",
        "        for feature, label in train_loader:\n",
        "            feature = feature.to(torch.device('cuda')).float()\n",
        "            label = label.to(torch.device('cuda'))\n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(True):\n",
        "                output = model(feature)\n",
        "                loss = criterion(output, label)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            label = label.cpu().numpy()\n",
        "            pred = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
        "            train_loss += loss.item() * label.shape[0]\n",
        "            train_correct += np.sum(label == pred)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "        print('Epoch %d train loss %f accuracy %.4f' % (epoch, train_loss, train_acc))\n",
        "\n",
        "        model.eval()  # 預測模式\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        for feature, label in val_loader:\n",
        "            feature = feature.to(torch.device('cuda')).float()\n",
        "            label = label.to(torch.device('cuda'))\n",
        "            with torch.set_grad_enabled(False):\n",
        "                if len(feature.size()) == 5:  # test time augmentation 用\n",
        "                    B, T, C, H, W = feature.size()\n",
        "                    output = model(feature.view(-1, C, H, W))\n",
        "                    output = output.view(B, T, -1)\n",
        "                    output = output.mean(dim=1)\n",
        "                else:\n",
        "                    output = model(feature)\n",
        "                loss = criterion(output, label)\n",
        "            label = label.cpu().numpy()\n",
        "            pred = np.argmax(output.cpu().numpy(), axis=1)\n",
        "            val_loss += loss.item() * label.shape[0]\n",
        "            val_correct += np.sum(label == pred)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "        print('Epoch %d validation loss %f accuracy %.4f' % (epoch, val_loss, val_acc))\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_epoch = epoch\n",
        "            # 儲存當前 validation 最好的模型\n",
        "            if name is not None:\n",
        "                torch.save({'model': model.state_dict()}, name)\n",
        "\n",
        "        if epoch - best_epoch >= patient:\n",
        "            # 當 patient 個 epoch 沒有進步後，跳出迴圈停止訓練\n",
        "            print('Best epoch %d' % best_epoch)\n",
        "            break\n",
        "\n",
        "def eval_model(model, test_dataset, batch_size=64):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    model.eval()\n",
        "    loss = 0.0\n",
        "    correct = 0\n",
        "    for feature, label in test_loader:\n",
        "        feature = feature.to(torch.device('cuda')).float()\n",
        "        label = label.to(torch.device('cuda'))\n",
        "        with torch.set_grad_enabled(False):\n",
        "            if len(feature.size()) == 5:  # test time augmentation 用\n",
        "                B, T, C, H, W = feature.size()\n",
        "                output = model(feature.view(-1, C, H, W))\n",
        "                output = output.view(B, T, -1)\n",
        "                output = output.mean(dim=1)\n",
        "            else:\n",
        "                output = model(feature)\n",
        "        label = label.cpu().numpy()\n",
        "        pred = np.argmax(output.cpu().numpy(), axis=1)\n",
        "        correct += np.sum(label == pred)\n",
        "    acc = correct / len(test_loader.dataset)\n",
        "    print('Test accuracy %.4f' % acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lilGuY_4dPyt",
        "outputId": "8ebe283e-a2b8-4f29-bc0b-362fecb88c6c"
      },
      "source": [
        "train_dataset = CifarDataset(train_feature, train_label)\n",
        "val_dataset = CifarDataset(val_feature, val_label)\n",
        "test_dataset = CifarDataset(test_feature, test_label)\n",
        "\n",
        "train_model(ConvNet, train_dataset, val_dataset, name='model.ckpt')\n",
        "model_ckpt = torch.load('model.ckpt')\n",
        "model = ConvNet()\n",
        "model.cuda()\n",
        "model.load_state_dict(model_ckpt['model'])\n",
        "eval_model(model, test_dataset)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 train loss 2.353386 accuracy 0.2661\n",
            "Epoch 0 validation loss 1.588211 accuracy 0.4306\n",
            "Epoch 1 train loss 1.476576 accuracy 0.4694\n",
            "Epoch 1 validation loss 1.444263 accuracy 0.4898\n",
            "Epoch 2 train loss 1.361184 accuracy 0.5208\n",
            "Epoch 2 validation loss 1.413498 accuracy 0.5036\n",
            "Epoch 3 train loss 1.286010 accuracy 0.5497\n",
            "Epoch 3 validation loss 1.266479 accuracy 0.5506\n",
            "Epoch 4 train loss 1.233907 accuracy 0.5677\n",
            "Epoch 4 validation loss 1.245590 accuracy 0.5644\n",
            "Epoch 5 train loss 1.192825 accuracy 0.5862\n",
            "Epoch 5 validation loss 1.219138 accuracy 0.5814\n",
            "Epoch 6 train loss 1.151678 accuracy 0.6018\n",
            "Epoch 6 validation loss 1.292943 accuracy 0.5624\n",
            "Epoch 7 train loss 1.117889 accuracy 0.6125\n",
            "Epoch 7 validation loss 1.240648 accuracy 0.5724\n",
            "Epoch 8 train loss 1.087696 accuracy 0.6278\n",
            "Epoch 8 validation loss 1.267286 accuracy 0.5732\n",
            "Epoch 9 train loss 1.085124 accuracy 0.6266\n",
            "Epoch 9 validation loss 1.297099 accuracy 0.5742\n",
            "Epoch 10 train loss 1.073895 accuracy 0.6302\n",
            "Epoch 10 validation loss 1.443501 accuracy 0.5506\n",
            "Best epoch 5\n",
            "Test accuracy 0.5715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlm8y4VgGqj_"
      },
      "source": [
        "成效不理想，出了什麼問題？ (To be continue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1tGEQaLXWFg"
      },
      "source": [
        "**重要！將輸入 normalize 到 mean 0 std 1, 增加數值穩定度**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02GSzFvodd3S",
        "outputId": "f61d7ba3-67d6-4b6c-e7b6-6944a5a847b5"
      },
      "source": [
        "train_mean = np.mean(train_feature, axis=(0, 1, 2))\n",
        "train_std = 0.0\n",
        "for i in range(train_feature.shape[0]):\n",
        "    train_std += np.std(train_feature[i], axis=(0, 1))\n",
        "train_std /= train_feature.shape[0]\n",
        "print(train_mean, train_std)\n",
        "\n",
        "train_dataset = CifarDataset(train_feature, train_label, train_mean=train_mean, train_std=train_std)\n",
        "val_dataset = CifarDataset(val_feature, val_label, train_mean=train_mean, train_std=train_std)\n",
        "test_dataset = CifarDataset(test_feature, test_label, train_mean=train_mean, train_std=train_std)\n",
        "\n",
        "train_model(ConvNet, train_dataset, val_dataset, name='model.ckpt')\n",
        "model_ckpt = torch.load('model.ckpt')\n",
        "model = ConvNet()\n",
        "model.cuda()\n",
        "model.load_state_dict(model_ckpt['model'])\n",
        "eval_model(model, test_dataset)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[125.26686406 122.93561814 113.87160816] [51.56650806 50.83678305 51.24483007]\n",
            "Epoch 0 train loss 1.403102 accuracy 0.4997\n",
            "Epoch 0 validation loss 1.209732 accuracy 0.5894\n",
            "Epoch 1 train loss 1.079814 accuracy 0.6224\n",
            "Epoch 1 validation loss 1.039771 accuracy 0.6378\n",
            "Epoch 2 train loss 0.951679 accuracy 0.6718\n",
            "Epoch 2 validation loss 0.938765 accuracy 0.6818\n",
            "Epoch 3 train loss 0.872921 accuracy 0.7002\n",
            "Epoch 3 validation loss 0.939741 accuracy 0.6728\n",
            "Epoch 4 train loss 0.816147 accuracy 0.7178\n",
            "Epoch 4 validation loss 0.897427 accuracy 0.6866\n",
            "Epoch 5 train loss 0.769172 accuracy 0.7355\n",
            "Epoch 5 validation loss 0.904213 accuracy 0.6918\n",
            "Epoch 6 train loss 0.728024 accuracy 0.7468\n",
            "Epoch 6 validation loss 0.888325 accuracy 0.7024\n",
            "Epoch 7 train loss 0.703850 accuracy 0.7561\n",
            "Epoch 7 validation loss 0.869151 accuracy 0.7038\n",
            "Epoch 8 train loss 0.666076 accuracy 0.7652\n",
            "Epoch 8 validation loss 0.870893 accuracy 0.7080\n",
            "Epoch 9 train loss 0.647185 accuracy 0.7750\n",
            "Epoch 9 validation loss 0.909803 accuracy 0.6976\n",
            "Epoch 10 train loss 0.615364 accuracy 0.7838\n",
            "Epoch 10 validation loss 0.883172 accuracy 0.7050\n",
            "Epoch 11 train loss 0.593275 accuracy 0.7944\n",
            "Epoch 11 validation loss 0.912935 accuracy 0.7056\n",
            "Epoch 12 train loss 0.565919 accuracy 0.8013\n",
            "Epoch 12 validation loss 0.900278 accuracy 0.7034\n",
            "Best epoch 7\n",
            "Test accuracy 0.7083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wK8OCBalI1m"
      },
      "source": [
        "Data Augmentation\n",
        "\n",
        "因為類神經網路通常參數很多，需要大量資料來訓練，一般都會做 data augmentation 增加資料量\n",
        "\n",
        "以影像來說，就是做旋轉、縮放、翻轉等，稍微改變影像，但是不影響他的答案或是要知道新的答案(為什麼？)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRTi7OalvyN"
      },
      "source": [
        "# 這邊使用 albumentations 做 data augmentation\n",
        "from albumentations import Compose, Normalize, GaussianBlur, ShiftScaleRotate, HorizontalFlip, PadIfNeeded, CenterCrop\n",
        "\n",
        "\n",
        "class AugmentedDataset(Dataset):\n",
        "    def __init__(self, feature, label=None, train_mean=None, train_std=None, transform=[]):\n",
        "        self.feature = feature\n",
        "        self.label = label\n",
        "        self.train_mean = train_mean\n",
        "        self.train_std = train_std\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.feature[idx]\n",
        "        if self.train_mean is not None and self.train_std is not None:\n",
        "            feature = (feature - self.train_mean) / self.train_std\n",
        "        feature = Compose(self.transform)(image=feature)['image']\n",
        "        feature = np.transpose(feature, (2, 0, 1))\n",
        "        if self.label is not None:\n",
        "            return feature, self.label[idx]\n",
        "        else:\n",
        "            return feature\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.feature.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CviAAKv6KYTg",
        "outputId": "9f8d0803-fb76-4f9e-ebc8-1ec729990483"
      },
      "source": [
        "transform = [\n",
        "    ShiftScaleRotate(shift_limit=0.0, scale_limit=0.2, rotate_limit=2.5, p=0.5),\n",
        "    HorizontalFlip(p=0.5),  # 文字資料(中、英、日文等)不能 flip，為什麼？\n",
        "    # GaussianBlur(blur_limit=3, p=1.0),  #  如果圖片大一點可以考慮加 Gaussian Blur\n",
        "    PadIfNeeded(min_height=32, min_width=32, p=1.0),\n",
        "    CenterCrop(height=32, width=32),\n",
        "]\n",
        "train_dataset = AugmentedDataset(train_feature, train_label, train_mean=train_mean, train_std=train_std, transform=transform)\n",
        "val_dataset = CifarDataset(val_feature, val_label, train_mean=train_mean, train_std=train_std)\n",
        "test_dataset = CifarDataset(test_feature, test_label, train_mean=train_mean, train_std=train_std)\n",
        "\n",
        "train_model(ConvNet, train_dataset, val_dataset, name='model.ckpt')\n",
        "model_ckpt = torch.load('model.ckpt')\n",
        "model = ConvNet()\n",
        "model.cuda()\n",
        "model.load_state_dict(model_ckpt['model'])\n",
        "eval_model(model, test_dataset)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 train loss 1.451866 accuracy 0.4809\n",
            "Epoch 0 validation loss 1.241139 accuracy 0.5548\n",
            "Epoch 1 train loss 1.162299 accuracy 0.5939\n",
            "Epoch 1 validation loss 1.101607 accuracy 0.6124\n",
            "Epoch 2 train loss 1.067289 accuracy 0.6305\n",
            "Epoch 2 validation loss 1.043179 accuracy 0.6362\n",
            "Epoch 3 train loss 1.011618 accuracy 0.6484\n",
            "Epoch 3 validation loss 0.992615 accuracy 0.6530\n",
            "Epoch 4 train loss 0.968768 accuracy 0.6663\n",
            "Epoch 4 validation loss 1.000878 accuracy 0.6626\n",
            "Epoch 5 train loss 0.937565 accuracy 0.6766\n",
            "Epoch 5 validation loss 0.925367 accuracy 0.6824\n",
            "Epoch 6 train loss 0.914794 accuracy 0.6841\n",
            "Epoch 6 validation loss 0.908713 accuracy 0.6810\n",
            "Epoch 7 train loss 0.888267 accuracy 0.6928\n",
            "Epoch 7 validation loss 0.896639 accuracy 0.6896\n",
            "Epoch 8 train loss 0.874781 accuracy 0.6973\n",
            "Epoch 8 validation loss 0.936717 accuracy 0.6792\n",
            "Epoch 9 train loss 0.860663 accuracy 0.7018\n",
            "Epoch 9 validation loss 0.890760 accuracy 0.6992\n",
            "Epoch 10 train loss 0.850037 accuracy 0.7052\n",
            "Epoch 10 validation loss 0.904360 accuracy 0.6896\n",
            "Epoch 11 train loss 0.842803 accuracy 0.7087\n",
            "Epoch 11 validation loss 0.876666 accuracy 0.6934\n",
            "Epoch 12 train loss 0.823460 accuracy 0.7155\n",
            "Epoch 12 validation loss 0.844262 accuracy 0.7126\n",
            "Epoch 13 train loss 0.817287 accuracy 0.7159\n",
            "Epoch 13 validation loss 0.877108 accuracy 0.6998\n",
            "Epoch 14 train loss 0.803693 accuracy 0.7220\n",
            "Epoch 14 validation loss 0.861917 accuracy 0.7082\n",
            "Epoch 15 train loss 0.803807 accuracy 0.7214\n",
            "Epoch 15 validation loss 0.861086 accuracy 0.7080\n",
            "Epoch 16 train loss 0.792007 accuracy 0.7242\n",
            "Epoch 16 validation loss 0.859702 accuracy 0.7054\n",
            "Epoch 17 train loss 0.783769 accuracy 0.7285\n",
            "Epoch 17 validation loss 0.818215 accuracy 0.7214\n",
            "Epoch 18 train loss 0.785431 accuracy 0.7299\n",
            "Epoch 18 validation loss 0.824453 accuracy 0.7194\n",
            "Epoch 19 train loss 0.770045 accuracy 0.7341\n",
            "Epoch 19 validation loss 0.857098 accuracy 0.7072\n",
            "Epoch 20 train loss 0.763446 accuracy 0.7363\n",
            "Epoch 20 validation loss 0.863767 accuracy 0.7050\n",
            "Epoch 21 train loss 0.755070 accuracy 0.7388\n",
            "Epoch 21 validation loss 0.809521 accuracy 0.7226\n",
            "Epoch 22 train loss 0.750603 accuracy 0.7407\n",
            "Epoch 22 validation loss 0.843994 accuracy 0.7108\n",
            "Epoch 23 train loss 0.744865 accuracy 0.7412\n",
            "Epoch 23 validation loss 0.827130 accuracy 0.7186\n",
            "Epoch 24 train loss 0.731798 accuracy 0.7471\n",
            "Epoch 24 validation loss 0.821325 accuracy 0.7172\n",
            "Epoch 25 train loss 0.729714 accuracy 0.7468\n",
            "Epoch 25 validation loss 0.884709 accuracy 0.7012\n",
            "Epoch 26 train loss 0.730247 accuracy 0.7493\n",
            "Epoch 26 validation loss 0.840560 accuracy 0.7186\n",
            "Best epoch 21\n",
            "Test accuracy 0.7246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flboObn1anhd"
      },
      "source": [
        "Test Time Augmentation (TTA):\n",
        "\n",
        "預測時使用多張圖片，並將他們的預測值做平均"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8mI9LP_KamYH",
        "outputId": "72751572-9c51-4665-f7e5-2686d36e5e84"
      },
      "source": [
        "class TTADataset(Dataset):\n",
        "    def __init__(self, feature, label=None, train_mean=None, train_std=None, transform=[]):\n",
        "        self.feature = feature\n",
        "        self.label = label\n",
        "        self.train_mean = train_mean\n",
        "        self.train_std = train_std\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.feature[idx]\n",
        "        if self.train_mean is not None and self.train_std is not None:\n",
        "            feature = (feature - self.train_mean) / self.train_std\n",
        "        features = [feature]\n",
        "        features.append(HorizontalFlip(always_apply=True)(image=feature)['image'])\n",
        "        features = np.stack(features, axis=0)\n",
        "        features = np.transpose(features, (0, 3, 1, 2))\n",
        "        if self.label is not None:\n",
        "            return features, self.label[idx]\n",
        "        else:\n",
        "            return features\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.feature.shape[0]\n",
        "  \n",
        "val_dataset = TTADataset(val_feature, val_label, train_mean=train_mean, train_std=train_std)\n",
        "test_dataset = TTADataset(test_feature, test_label, train_mean=train_mean, train_std=train_std)\n",
        "\n",
        "model_ckpt = torch.load('model.ckpt')\n",
        "model = ConvNet()\n",
        "model.cuda()\n",
        "model.load_state_dict(model_ckpt['model'])\n",
        "eval_model(model, val_dataset)\n",
        "eval_model(model, test_dataset)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 0.7470\n",
            "Test accuracy 0.7403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFLNzGqn3XV2"
      },
      "source": [
        "預訓練模型 (Pretrained Model)\n",
        "\n",
        "使用 Imagenet 資料預先訓練好的模型\n",
        "\n",
        "什麼是 Imagenet：http://www.image-net.org/ https://zh.wikipedia.org/zh-tw/ImageNet\n",
        "\n",
        "PyTorch 內建：https://pytorch.org/docs/stable/torchvision/models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DzjB8tyLgLec"
      },
      "source": [
        "from torchvision import models\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self, n_class=10):\n",
        "        super(Resnet, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_ftrs, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model.forward(x)\n",
        "\n",
        "class ResnetScratch(nn.Module):\n",
        "    def __init__(self, n_class=10):\n",
        "        super(ResnetScratch, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=False)\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_ftrs, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model.forward(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwYpIGDCg4Gi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53ec6d7-0419-4bac-a8ad-e6c2d5e13e89"
      },
      "source": [
        "transform = [\n",
        "    ShiftScaleRotate(shift_limit=0.0, scale_limit=0.2, rotate_limit=2.5, p=0.5),\n",
        "    HorizontalFlip(p=0.5),  # 文字資料(中、英、日文等)不能 flip，為什麼？\n",
        "    # GaussianBlur(blur_limit=3, p=1.0),  #  如果圖片大一點可以考慮加 Gaussian Blur\n",
        "    PadIfNeeded(min_height=32, min_width=32, p=1.0),\n",
        "    CenterCrop(height=32, width=32),\n",
        "]\n",
        "train_dataset = AugmentedDataset(train_feature, train_label, train_mean=train_mean, train_std=train_std, transform=transform)\n",
        "val_dataset = TTADataset(val_feature, val_label, train_mean=train_mean, train_std=train_std)\n",
        "test_dataset = TTADataset(test_feature, test_label, train_mean=train_mean, train_std=train_std)\n",
        "\n",
        "train_model(ResnetScratch, train_dataset, val_dataset, name='model.ckpt')\n",
        "model_ckpt = torch.load('model.ckpt')\n",
        "model = ResnetScratch()\n",
        "model.cuda()\n",
        "model.load_state_dict(model_ckpt['model'])\n",
        "eval_model(model, test_dataset)\n",
        "\n",
        "# imagenet pretrained 用的 mean / std https://github.com/pytorch/examples/blob/97304e232807082c2e7b54c597615dc0ad8f6173/imagenet/main.py#L197-L198\n",
        "imagenet_mean = np.array([0.485, 0.456, 0.406]) * 255\n",
        "imagenet_std = np.array([0.229, 0.224, 0.225]) * 255\n",
        "train_dataset = AugmentedDataset(train_feature, train_label, train_mean=imagenet_mean, train_std=imagenet_std, transform=transform)\n",
        "val_dataset = TTADataset(val_feature, val_label, train_mean=imagenet_mean, train_std=imagenet_std)\n",
        "test_dataset = TTADataset(test_feature, test_label, train_mean=imagenet_mean, train_std=imagenet_std)\n",
        "\n",
        "train_model(Resnet, train_dataset, val_dataset, name='model.ckpt')\n",
        "model_ckpt = torch.load('model.ckpt')\n",
        "model = Resnet()\n",
        "model.cuda()\n",
        "model.load_state_dict(model_ckpt['model'])\n",
        "eval_model(model, test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 train loss 1.447758 accuracy 0.4808\n",
            "Epoch 0 validation loss 1.105800 accuracy 0.6180\n",
            "Epoch 1 train loss 1.080669 accuracy 0.6214\n",
            "Epoch 1 validation loss 0.946029 accuracy 0.6682\n",
            "Epoch 2 train loss 0.921757 accuracy 0.6816\n",
            "Epoch 2 validation loss 0.816221 accuracy 0.7074\n",
            "Epoch 3 train loss 0.813312 accuracy 0.7184\n",
            "Epoch 3 validation loss 0.757172 accuracy 0.7358\n",
            "Epoch 4 train loss 0.735773 accuracy 0.7462\n",
            "Epoch 4 validation loss 0.714444 accuracy 0.7502\n",
            "Epoch 5 train loss 0.710436 accuracy 0.7516\n",
            "Epoch 5 validation loss 0.660476 accuracy 0.7712\n",
            "Epoch 6 train loss 0.626385 accuracy 0.7810\n",
            "Epoch 6 validation loss 0.651326 accuracy 0.7720\n",
            "Epoch 7 train loss 0.580681 accuracy 0.7997\n",
            "Epoch 7 validation loss 0.580399 accuracy 0.8002\n",
            "Epoch 8 train loss 0.540950 accuracy 0.8119\n",
            "Epoch 8 validation loss 0.572364 accuracy 0.8008\n",
            "Epoch 9 train loss 0.502599 accuracy 0.8274\n",
            "Epoch 9 validation loss 0.633677 accuracy 0.7878\n",
            "Epoch 10 train loss 0.465658 accuracy 0.8386\n",
            "Epoch 10 validation loss 0.556364 accuracy 0.8098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBr1HXvQEtLV"
      },
      "source": [
        "比 Imagenet 更厲害的預訓練模型：Instagram pretrained https://github.com/facebookresearch/WSL-Images (ECCV 2018 by Facebook team)"
      ]
    }
  ]
}